{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "\n",
    "\n",
    "def select_features(df, labels, features, n_features):\n",
    "    ## create empty lists as placeholders\n",
    "    grouped_features = []\n",
    "    for i in range(n_features):\n",
    "        new = []\n",
    "        grouped_features.append(new)\n",
    "\n",
    "    for i in range(len(features)):\n",
    "        grouped_features[labels[i]].append(features[i])\n",
    "\n",
    "    selected_features = []\n",
    "    for fs in grouped_features:\n",
    "        matrix = df[fs].corr().abs()\n",
    "        max_f_id = matrix.sum(axis=1).argmax()\n",
    "        selected_features.append(fs[max_f_id])\n",
    "        \n",
    "    return selected_features\n",
    "\n",
    "# sort the df to traces for every subject and goals\n",
    "def extract_traces(dfn):\n",
    "    traces = []\n",
    "\n",
    "    Subject = 0\n",
    "    Loc = 0\n",
    "    Iteration = 0\n",
    "    tup = (Subject, Loc, Iteration)\n",
    "\n",
    "    for index, row in dfn.iterrows():\n",
    "        curr_Subject = row[\"Subject\"]\n",
    "        curr_Loc = row[\"Loc\"]\n",
    "        curr_Iteration = row[\"Iteration\"]\n",
    "        curr_tup = (curr_Subject, curr_Loc, curr_Iteration)\n",
    "\n",
    "        if curr_tup != tup:\n",
    "            #print(\"new trace\")\n",
    "            tup = curr_tup\n",
    "\n",
    "            rslt_df = dfn[(dfn['Subject'] == curr_Subject) \n",
    "                      & (dfn['Loc'] == curr_Loc) \n",
    "                      & (dfn['Iteration'] == curr_Iteration)]\n",
    "\n",
    "            rslt_df.reset_index(drop=True, inplace=True)\n",
    "            traces.append(rslt_df)\n",
    "            \n",
    "    return traces\n",
    "\n",
    "\n",
    "def convert_labels_kmeans(traces, goals, subject_id):\n",
    "    # generate classifiers here\n",
    "    \n",
    "    subtraces = []\n",
    "    for goal in goals:\n",
    "        subtraces_goalX = []\n",
    "        for t in traces:\n",
    "            if t[\"Subject\"][0] == subject_id and t[\"Loc\"][0] == goal:\n",
    "                converted_trace = []\n",
    "                \n",
    "                for index,e in t.iterrows():\n",
    "                    converted_trace.append( e[\"class\"] )\n",
    "                                        \n",
    "                subtraces_goalX.append(converted_trace)\n",
    "        subtraces.append(subtraces_goalX)\n",
    "            \n",
    "    return subtraces\n",
    "\n",
    "\n",
    "\n",
    "############################# file system helpers ########################\n",
    "\n",
    "# random.randint(0,2)\n",
    "\n",
    "def reCreateDir(dirName):\n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(dirName)\n",
    "    if isExist:\n",
    "        # delete\n",
    "        shutil.rmtree(dirName)\n",
    "    \n",
    "    os.makedirs(dirName)\n",
    "    \n",
    "    \n",
    "# write sas_plan\n",
    "def write_plan(actions, file):\n",
    "    string = \"\"\n",
    "    for a in actions:\n",
    "        string += \"%s\\n\" % (str(a))\n",
    "    string += \"; cost %s (unit cost)\" % (str(len(actions)))\n",
    "    \n",
    "    file1 = open(file, \"w\")\n",
    "    file1.write(string)\n",
    "    file1.close()\n",
    "    return 0\n",
    "        \n",
    "# write_plan(subtraces_goal2[1], \"sas_plan.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/cluster/_agglomerative.py:983: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# parameters:\n",
    "input_data = \"examplef30.csv\"\n",
    "index_headers = 4\n",
    "n_features = 15\n",
    "\n",
    "n_init = 20\n",
    "n_clusters = 10\n",
    "subject_id = 10\n",
    "\n",
    "# recognizer param:\n",
    "phi = 50\n",
    "lamb = 1.5\n",
    "delta = 1.0\n",
    "theta = 0.9\n",
    "\n",
    "\n",
    "# dependent\n",
    "output_results = \"example_c%s_f%s.csv\" % (str(n_clusters), str(n_features))\n",
    "\n",
    "\n",
    "# main script\n",
    "df = pd.read_csv(input_data)\n",
    "\n",
    "## the number of irrelevant features : index_headers\n",
    "all_features = df.columns.values.tolist()[index_headers::]\n",
    "df_context = df[all_features]\n",
    "    \n",
    "############################## select features ##############################\n",
    "corr_matrix = df_context.corr().abs()\n",
    "hierarchical_cluster = AgglomerativeClustering(n_clusters=n_features, affinity='euclidean', linkage='ward').fit(corr_matrix)\n",
    "labels = hierarchical_cluster.labels_\n",
    "\n",
    "selected_features = select_features(df, labels, all_features, n_features)\n",
    "#selected_features = all_features\n",
    "############################## classification ###########################\n",
    "# analyze by subject:\n",
    "df_a_subject = df.loc[df['Subject'] == subject_id].reset_index(drop=True)\n",
    "df_a_subject_index = df_a_subject[[\"Subject\", \"Loc\", \"Iteration\"]]\n",
    "\n",
    "reduced = df_a_subject[selected_features]\n",
    "\n",
    "# get average length  ?????  decide how many classes to set\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Set the random seed\n",
    "\n",
    "if n_clusters > len(reduced):\n",
    "    print(\"to many\")\n",
    "    # exit()\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=n_init).fit(reduced)\n",
    "df_classes = pd.DataFrame(kmeans.labels_, columns = ['class'])\n",
    "df_classified = pd.concat([df_a_subject_index, df_classes], axis=1)\n",
    "\n",
    "traces = extract_traces(df_classified)    \n",
    "goals = list(df_classified[\"Loc\"].unique())\n",
    "goals.sort()\n",
    "subtraces = convert_labels_kmeans(traces, goals, subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 1, 2, 4, 2, 7, 1],\n",
       " [8, 7, 4, 4, 2, 7, 1, 8, 8],\n",
       " [8, 1, 2, 4, 4, 7, 1, 8],\n",
       " [1, 2, 4, 4, 2, 7, 1, 8]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtraces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 7, 0, 9, 0, 5, 6, 6, 6],\n",
       " [8, 1, 7, 0, 3, 3, 5, 6],\n",
       " [8, 7, 0, 9, 9, 0, 5, 6, 6],\n",
       " [1, 7, 4, 9, 9, 0, 5, 6]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtraces[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miner starts\n",
      "../model/0.xes\n",
      "../model/1.xes\n",
      "mining complete\n",
      "model/0.xes.pnml : indexed\n",
      "model/1.xes.pnml : indexed\n",
      "done\n",
      "model/0.xes.pnml : indexed\n",
      "model/1.xes.pnml : indexed\n",
      "done\n",
      "model/0.xes.pnml : indexed\n",
      "model/1.xes.pnml : indexed\n",
      "done\n",
      "model/0.xes.pnml : indexed\n",
      "model/1.xes.pnml : indexed\n",
      "done\n",
      "model/0.xes.pnml : indexed\n",
      "model/1.xes.pnml : indexed\n",
      "done\n",
      "model/0.xes.pnml : indexed\n",
      "model/1.xes.pnml : indexed\n",
      "done\n",
      "model/0.xes.pnml : indexed\n",
      "model/1.xes.pnml : indexed\n",
      "done\n",
      "model/0.xes.pnml : indexed\n",
      "model/1.xes.pnml : indexed\n",
      "done\n",
      "model/0.xes.pnml : indexed\n",
      "model/1.xes.pnml : indexed\n",
      "done\n",
      "model/0.xes.pnml : indexed\n",
      "model/1.xes.pnml : indexed\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"rm -rf %s\" % output_results)\n",
    "\n",
    "\n",
    "reCreateDir(\"test\")\n",
    "reCreateDir(\"model\")\n",
    "\n",
    "test_id = 3\n",
    "goal_id = 0\n",
    "for a_goal in subtraces:\n",
    "    reCreateDir(\"goal_%s\" % str(goal_id) )\n",
    "    trace_id = 0\n",
    "    for a_trace in a_goal:\n",
    "        write_plan(a_trace, \"goal_%s/sas_plan.%s\" % (str(goal_id), str(trace_id)) )\n",
    "        trace_id += 1\n",
    "\n",
    "    # test\n",
    "    os.system(\"mv goal_%s/sas_plan.%s test/sas_plan.%s\" % (str(goal_id), str(test_id), str(goal_id)) )\n",
    "    # model\n",
    "    os.system(\"java -jar sas2xes.jar goal_%s model/%s.xes\" % (str(goal_id), str(goal_id)) )\n",
    "    goal_id += 1\n",
    "\n",
    "os.chdir(\"./miningPNMLS\")\n",
    "os.system(\"java -jar mine_all_pnmls.jar -DFM ../model/ 0.8\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "\n",
    "for i in range(len(subtraces)):\n",
    "    # goal_id, goal_id, percentage\n",
    "    for percentage in [0.1,0.3,0.5,0.7,1.0]:\n",
    "        os.system(\"java -jar recognizer.jar -w model/ test/sas_plan.%s %s %s %s %s %s %s %s\" \n",
    "                  %(str(i), str(i), str(percentage), str(phi), str(lamb), str(delta), str(theta), str(output_results) )   )  \n",
    "\n",
    "os.system(\"rm -rf Feedback\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
